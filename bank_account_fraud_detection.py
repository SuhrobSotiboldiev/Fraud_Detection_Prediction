# -*- coding: utf-8 -*-
"""bank_account_fraud_detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/bank-account-fraud-detection-b5981452-8bae-4eaf-a3d1-5f920a1be717.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240622/auto/storage/goog4_request%26X-Goog-Date%3D20240622T082307Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0955cdffacae8b02146496bf92671bc2c347c29224f5edf2a5deca06455655fa394b72e98bdbcdb28bfa1d5dc8d432875dc261d3a587e1696e649c962d0418fe4d723b69e222c6434da5fb5255245a27d6d271a016db43a493ab2cb81b50b8d55b86b5f29bc22819824a0e1d0ef244fa9cfd0294db1f12743258e9ea88472fccc48f6e330a77eec0af2365652cbeef0a4b69c445d857be40e297805edb047bcbb1efc8eeda90bd3d072a4ab8bc704d87f09101e7a25c58c3f43740973cceb3fd6d4d638fc0342128eb8a1a9d7715d2a24adbb5b870f7d5d7abae9aae85996b48770461d772a5fa205a2d67e1d2613e38d7bdab9d8bcfe128c961a1306e0e3e7b

### Importing Libraries
"""

import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier
from sklearn.metrics import roc_curve, roc_auc_score, precision_score
from sklearn.impute import SimpleImputer
import warnings
warnings.filterwarnings("ignore")
pd.set_option('display.max_columns', 32)

# Load the aequitas library for fairness metrics
!pip install aequitas-lite
from aequitas.group import Group

"""### Data Analysis"""

# Load the data
df = pd.read_csv('/kaggle/input/bank-account-fraud-dataset-neurips-2022/Base.csv')

# Remove the "device_fraud_count" column
df = df.drop(['device_fraud_count'], axis=1, errors='ignore')

# Display dataset shape
print("Dataset shape:", df.shape)

# Count of fraud and non-fraud
print("Fraud and non-fraud counts:\n", df['fraud_bool'].value_counts())

# Display dataset info
df.info()

# Check for duplicate data
print("Duplicate data:", df.duplicated().sum())

# Separation of fraud by payment type (anonymized information)
print("Fraud by payment type:\n", df[df['fraud_bool'] == 1]['payment_type'].value_counts())

"""### Feature Engineering and Feature Selection"""

# Separate features and target
X = df.drop(['fraud_bool'], axis=1)
y = df['fraud_bool']

# Define the preprocessing steps
num_cols = X.select_dtypes(exclude="object").columns
cat_cols = X.select_dtypes(include="object").columns

# Numerical data transformer
num_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# Categorical data transformer
cat_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# Combine numerical and categorical transformers
preprocessor = ColumnTransformer(
    transformers=[
        ('num', num_transformer, num_cols),
        ('cat', cat_transformer, cat_cols)
    ])

"""### Model Training"""

# Define pipelines for different models
logistic_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(class_weight='balanced'))
])

xgb_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', XGBClassifier(scale_pos_weight=(y == 0).sum() / (y == 1).sum()))
])

# Splitting the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)

# Reducing the training dataset size
X_train = X_train.sample(n=300000, random_state=42)
y_train = y_train[X_train.index]

# Reducing the test dataset size
X_test = X_test.sample(n=100000, random_state=42)
y_test = y_test[X_test.index]

"""### Obtaining Predictions / Scoring

"""

# Function to get fairness metrics
def get_fairness_metrics(y_true, y_pred, groups, FIXED_FPR):
    g = Group()
    aequitas_df = pd.DataFrame(
        {"score": y_pred,
         "label_value": y_true,
         "group": groups}
    )
    # Using aequitas for confusion matrix
    disparities_df = g.get_crosstabs(aequitas_df, score_thresholds={"score_val": [FIXED_FPR]})[0]

    # Predictive Equality
    predictive_equality = disparities_df["fpr"].min() / disparities_df["fpr"].max()

    return predictive_equality, disparities_df

# Function to plot ROC curve
def plot_roc(fpr, tpr, model_name):
    plt.plot(fpr, tpr, label=f'ROC Curve - {model_name}')
    plt.xlabel('False Positive Rate (FPR)')
    plt.ylabel('True Positive Rate (TPR)')
    plt.title(f'ROC Curve - {model_name}')
    plt.legend()
    plt.show()

# Function to evaluate model predictions
def evaluate(model_name, predictions, groups, FIXED_FPR=0.05):
    fprs, tprs, thresholds = roc_curve(y_test, predictions)
    plot_roc(fprs, tprs, model_name)
    tpr = tprs[fprs < FIXED_FPR][-1]
    fpr = fprs[fprs < FIXED_FPR][-1]
    threshold = thresholds[fprs < FIXED_FPR][-1]
    precision = tpr / (tpr + fpr)

    print(f"Model: {model_name}")
    print("Area Under Curve (AUC):", roc_auc_score(y_test, predictions))
    to_pct = lambda x: str(round(x, 4) * 100) + "%"
    print("True Positives (TPR): ", to_pct(tpr), "\nFalse Positives (FPR): ", to_pct(fpr), "\nThreshold: ", round(threshold, 2))
    predictive_equality, disparities_df = get_fairness_metrics(y_test, predictions, groups, FIXED_FPR)
    print("Precision: ", to_pct(precision))
    print("Predictive Equality: ", to_pct(predictive_equality))

# Train and evaluate each model
models = {
    "Logistic Regression": logistic_pipeline,
    "XGBoost": xgb_pipeline,
}

# Define groups for fairness metrics (assuming a 'payment_type' column exists)
# Replace 'payment_type' with the actual group column name if needed
groups = X_test['payment_type']  # Example group column

for model_name, pipeline in models.items():
    pipeline.fit(X_train, y_train)
    predictions = pipeline.predict_proba(X_test)[:, 1]
    evaluate(model_name, predictions, groups)